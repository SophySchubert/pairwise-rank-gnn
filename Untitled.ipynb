{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8445d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spektral\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from spektral.data import DisjointLoader\n",
    "from spektral.data.loaders import tf_loader_available\n",
    "import scipy.sparse as sp\n",
    "from spektral.data.utils import (\n",
    "    prepend_none,\n",
    "    sp_matrices_to_sp_tensors,\n",
    "    to_disjoint,\n",
    "    collate_labels_disjoint\n",
    ")\n",
    "import numpy as np\n",
    "from ogb.graphproppred import GraphPropPredDataset\n",
    "from spektral.data import Dataset, Graph\n",
    "from spektral.datasets import TUDataset, QM9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6158171",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'seed': 1,\n",
    "    'epochs': 10,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'dataset': 'ogbg-molesol', #JA: QM9, ogbg-molesol, ogbg-molfreesolv, ogbg-mollipo, ZINC| NEIN: aspirin\n",
    "    'train_test_split': 0.8\n",
    "}\n",
    "\n",
    "np.random.seed(config['seed'])\n",
    "tf.random.set_seed(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9cd1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OGBDataset(Dataset):\n",
    "    '''\n",
    "    (spektral) Dataset class wrapper for Open Graph Benchmark datasets.\n",
    "    '''\n",
    "    def __init__(self, name, **kwargs):\n",
    "        self.name = name\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        dataset = GraphPropPredDataset(name=self.name)\n",
    "        graphs = []\n",
    "        for data in dataset:\n",
    "            edge_index = data[0]['edge_index']\n",
    "            edge_feat = data[0]['edge_feat']\n",
    "            node_feat = data[0]['node_feat']\n",
    "            label = data[1]\n",
    "\n",
    "            # Create adjacency matrix\n",
    "            num_nodes = node_feat.shape[0]\n",
    "            adj = np.zeros((num_nodes, num_nodes))\n",
    "            for edge in edge_index.T:\n",
    "                adj[edge[0], edge[1]] = 1\n",
    "\n",
    "            # Create spektral Graph object\n",
    "            graphs.append(Graph(x=node_feat, a=adj, e=edge_feat, y=label))\n",
    "\n",
    "        return graphs\n",
    "\n",
    "def ogb_available_datasets():\n",
    "    #These regression datasets have size % 2 == 0 number of graphs\n",
    "    return ['ogbg-molesol', 'ogbg-molfreesolv', 'ogbg-mollipo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5122967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(name: str):\n",
    "    '''\n",
    "    Loads a dataset from [TUDataset, OGB]\n",
    "    '''\n",
    "    if name == 'QM9':\n",
    "        dataset = QM9(amount=1000)# 1000 and 100000 ok\n",
    "    elif name in TUDataset.available_datasets():\n",
    "        dataset = TUDataset(name)\n",
    "    elif name in ogb_available_datasets():\n",
    "        dataset= OGBDataset(name)\n",
    "    else:\n",
    "        raise ValueError(f'Dataset {name} unknown')\n",
    "\n",
    "    return dataset, dataset.n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "313cc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_data(data, train_test_split, seed):\n",
    "    '''\n",
    "    Split the data into train and test sets\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    idxs = np.random.permutation(len(data))\n",
    "    split = int(train_test_split * len(data))\n",
    "    idx_train, idx_test = np.split(idxs, [split])\n",
    "    train, test = data[idx_train], data[idx_test]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bd00116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(config):\n",
    "    seed = config['seed']\n",
    "    train_test_split = config['train_test_split']\n",
    "    name = config['dataset']\n",
    "\n",
    "    # Load data\n",
    "    data, config['n_out'] = _load_data(name)\n",
    "    # Split data\n",
    "    train_data, test_data = _split_data(data, train_test_split, seed)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58deeaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_signature(signature):\n",
    "    \"\"\"\n",
    "    Converts a Dataset signature to a TensorFlow signature. Extended keys (idx_a, idx_b) for MyDisjointLoader.\n",
    "    :param signature: a Dataset signature.\n",
    "    :return: a TensorFlow signature.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    keys = [\"x\", \"a\", \"e\", \"i\", \"idx_a\", \"idx_b\"]\n",
    "    for k in keys:\n",
    "        if k in signature:\n",
    "            shape = signature[k][\"shape\"]\n",
    "            dtype = signature[k][\"dtype\"]\n",
    "            spec = signature[k][\"spec\"]\n",
    "            output.append(spec(shape, dtype))\n",
    "    output = tuple(output)\n",
    "    if \"y\" in signature:\n",
    "        shape = signature[\"y\"][\"shape\"]\n",
    "        dtype = signature[\"y\"][\"dtype\"]\n",
    "        spec = signature[\"y\"][\"spec\"]\n",
    "        output = (output, spec(shape, dtype))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b36b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDisjointLoader(DisjointLoader):\n",
    "    \"\"\"\n",
    "    Extension of DisjointLoader class from spektral library. Additionally to data and targets, it also returns ranking pair indices.\n",
    "    A Loader for [disjoint mode](https://graphneural.network/data-modes/#disjoint-mode).\n",
    "\n",
    "    This loader represents a batch of graphs via their disjoint union.\n",
    "\n",
    "    The loader automatically computes a batch index tensor, containing integer\n",
    "    indices that map each node to its corresponding graph in the batch.\n",
    "\n",
    "    The adjacency matrix os returned as a SparseTensor, regardless of the input.\n",
    "\n",
    "    If `node_level=False`, the labels are interpreted as graph-level labels and\n",
    "    are stacked along an additional dimension.\n",
    "    If `node_level=True`, then the labels are stacked vertically.\n",
    "\n",
    "    **Note:** TensorFlow 2.4 or above is required to use this Loader's `load()`\n",
    "    method in a Keras training loop.\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "    - `dataset`: a graph Dataset;\n",
    "    - `node_level`: bool, if `True` stack the labels vertically for node-level\n",
    "    prediction;\n",
    "    - `batch_size`: size of the mini-batches;\n",
    "    - `epochs`: number of epochs to iterate over the dataset. By default (`None`)\n",
    "    iterates indefinitely;\n",
    "    - `shuffle`: whether to shuffle the data at the start of each epoch.\n",
    "\n",
    "    **Output**\n",
    "\n",
    "    For each batch, returns a tuple `(inputs, labels)`.\n",
    "\n",
    "    `inputs` is a tuple containing:\n",
    "\n",
    "    - `x`: node attributes of shape `[n_nodes, n_node_features]`;\n",
    "    - `a`: adjacency matrices of shape `[n_nodes, n_nodes]`;\n",
    "    - `e`: edge attributes of shape `[n_edges, n_edge_features]`;\n",
    "    - `i`: batch index of shape `[n_nodes]`.\n",
    "\n",
    "    `labels` have shape `[batch, n_labels]` if `node_level=False` or\n",
    "    `[n_nodes, n_labels]` otherwise.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, dataset, node_level=False, batch_size=1, epochs=None, shuffle=True, seed=42, radius=4, sampling_ratio=100\n",
    "    ):\n",
    "        self.node_level = node_level\n",
    "        super().__init__(dataset, batch_size=batch_size, epochs=epochs, shuffle=shuffle)\n",
    "        self.seed = seed\n",
    "        self.radius = radius\n",
    "        self.sampling_ratio = sampling_ratio\n",
    "\n",
    "    def collate(self, batch):\n",
    "        idx_a, idx_b, target = self.sample_preference_pairs(batch, seed=self.seed, radius=self.radius, sampling_ratio=self.sampling_ratio)\n",
    "        packed = self.pack(batch)\n",
    "\n",
    "        y = packed.pop(\"y_list\", None)\n",
    "        if y is not None:\n",
    "            y = collate_labels_disjoint(y, node_level=self.node_level)\n",
    "\n",
    "        output = to_disjoint(**packed)\n",
    "        output = sp_matrices_to_sp_tensors(output)\n",
    "\n",
    "        return output + (idx_a, idx_b), target\n",
    "\n",
    "    def load(self):\n",
    "        print(\"load\")\n",
    "        if not tf_loader_available:\n",
    "            raise RuntimeError(\n",
    "                \"Calling DisjointLoader.load() requires \" \"TensorFlow 2.4 or greater.\"\n",
    "            )\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            lambda: self, output_signature=self.tf_signature()\n",
    "        )\n",
    "\n",
    "    def tf_signature(self):\n",
    "        \"\"\"\n",
    "        Adjacency matrix has shape [n_nodes, n_nodes]\n",
    "        Node features have shape [n_nodes, n_node_features]\n",
    "        Edge features have shape [n_edges, n_edge_features]\n",
    "        Targets have shape [*, n_labels]\n",
    "        Pairs have shape [*, 2]\n",
    "        \"\"\"\n",
    "        signature = self.dataset.signature\n",
    "        if \"y\" in signature:\n",
    "            signature[\"y\"][\"shape\"] = prepend_none(signature[\"y\"][\"shape\"]) #(12800,) #(None, 1)\n",
    "        if \"a\" in signature:\n",
    "            signature[\"a\"][\"spec\"] = tf.SparseTensorSpec\n",
    "\n",
    "        signature[\"i\"] = dict()\n",
    "        signature[\"i\"][\"spec\"] = tf.TensorSpec\n",
    "        signature[\"i\"][\"shape\"] = (None,)\n",
    "        signature[\"i\"][\"dtype\"] = tf.as_dtype(tf.int64)\n",
    "\n",
    "        signature[\"idx_a\"] = dict()\n",
    "        signature[\"idx_a\"][\"spec\"] = tf.TensorSpec\n",
    "        signature[\"idx_a\"][\"shape\"] = (None,)\n",
    "        signature[\"idx_a\"][\"dtype\"] = tf.as_dtype(tf.int64)\n",
    "        signature[\"idx_b\"] = dict()\n",
    "        signature[\"idx_b\"][\"spec\"] = tf.TensorSpec\n",
    "        signature[\"idx_b\"][\"shape\"] = (None,)\n",
    "        signature[\"idx_b\"][\"dtype\"] = tf.as_dtype(tf.int64)\n",
    "\n",
    "        return to_tf_signature(signature)\n",
    "\n",
    "    def sample_preference_pairs(self, graphs, radius=4, sampling_ratio=100, seed=42):\n",
    "        seed = self.seed\n",
    "        size = len(graphs)\n",
    "        sample_size = size * radius * sampling_ratio\n",
    "        r = np.arange(size)\n",
    "        S = sp.csr_matrix((r, (r, r)), shape=(size, size))\n",
    "        parts = np.split(S.data, S.indptr[1:-1])\n",
    "        rnd = np.random.default_rng(seed)\n",
    "        for part in parts:\n",
    "            rnd.shuffle(part)\n",
    "        idx_a = np.empty((sample_size,), dtype=np.int64)\n",
    "        idx_b = np.empty((sample_size,), dtype=np.int64)\n",
    "        target = np.ones((sample_size,), dtype=np.float64)\n",
    "        k = 0\n",
    "        for i in range(size):\n",
    "            part = parts[i]\n",
    "            psize = len(part)\n",
    "            for d in range(radius):\n",
    "                ni = (i + d + 1) % size\n",
    "                npart = parts[ni]\n",
    "                npsize = len(npart)\n",
    "                for j in range(sampling_ratio):\n",
    "                    npart_offset = np.roll(npart, d * sampling_ratio + j)\n",
    "                    idx_a[k:k + psize] = part\n",
    "                    if npsize < psize:\n",
    "                        idx_b[k:k + npsize] = npart_offset\n",
    "                        idx_b[k + npsize:k + psize] = npart_offset[:psize - npsize]\n",
    "                    else:\n",
    "                        idx_b[k:k + psize] = npart_offset[:psize]\n",
    "                    if ni < i:\n",
    "                        target[k:k + psize] = 0\n",
    "                    k += psize\n",
    "        return idx_a, idx_b, target.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3feb653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a437a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graphs, test_graphs = get_data(config)\n",
    "loader_tr = MyDisjointLoader(train_graphs, batch_size=config['batch_size'], epochs=config['epochs'], seed=config['seed'], radius=4, sampling_ratio=100)\n",
    "loader_te = MyDisjointLoader(test_graphs, batch_size=config['batch_size'], epochs=1, seed=config['seed'], radius=1, sampling_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b9cd6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myModel():\n",
    "    x,a,e,i,idx_a,idx_b = tf.keras.Input(shape=None)\n",
    "    print(idx_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9f7d2ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide to Input a `shape` or a `tensor` or a `type_spec` argument. Note that `shape` does not include the batch dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-cf9ac655d45c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-5f2bf74506f4>\u001b[0m in \u001b[0;36mmyModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/experiment/lib/python3.6/site-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m   if (batch_input_shape is None and shape is None and tensor is None\n\u001b[1;32m    369\u001b[0m       and type_spec is None):\n\u001b[0;32m--> 370\u001b[0;31m     raise ValueError('Please provide to Input a `shape`'\n\u001b[0m\u001b[1;32m    371\u001b[0m                      \u001b[0;34m' or a `tensor` or a `type_spec` argument. Note that '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                      \u001b[0;34m'`shape` does not include the batch '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide to Input a `shape` or a `tensor` or a `type_spec` argument. Note that `shape` does not include the batch dimension."
     ]
    }
   ],
   "source": [
    "m = myModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68274b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset shapes: (((None, 9), (None, None), (None, 3), (None,), (None,), (None,)), (None, 1)), types: ((tf.int64, tf.float64, tf.int64, tf.int64, tf.int64, tf.int64), tf.float64)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_tr.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d4a358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
