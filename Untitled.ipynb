{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8445d7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophia.schubert/miniconda3/envs/experiment/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spektral\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from spektral.data import DisjointLoader\n",
    "from spektral.data.loaders import tf_loader_available\n",
    "import scipy.sparse as sp\n",
    "from spektral.data.utils import (\n",
    "    prepend_none,\n",
    "    sp_matrices_to_sp_tensors,\n",
    "    to_disjoint,\n",
    "    collate_labels_disjoint\n",
    ")\n",
    "import numpy as np\n",
    "from ogb.graphproppred import GraphPropPredDataset\n",
    "from spektral.data import Dataset, Graph\n",
    "from spektral.datasets import TUDataset, QM9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6158171",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'seed': 1,\n",
    "    'epochs': 10,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'dataset': 'ogbg-molesol', #JA: QM9, ogbg-molesol, ogbg-molfreesolv, ogbg-mollipo, ZINC| NEIN: aspirin\n",
    "    'train_test_split': 0.8\n",
    "}\n",
    "\n",
    "np.random.seed(config['seed'])\n",
    "tf.random.set_seed(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9cd1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OGBDataset(Dataset):\n",
    "    '''\n",
    "    (spektral) Dataset class wrapper for Open Graph Benchmark datasets.\n",
    "    '''\n",
    "    def __init__(self, name, **kwargs):\n",
    "        self.name = name\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        dataset = GraphPropPredDataset(name=self.name)\n",
    "        graphs = []\n",
    "        for data in dataset:\n",
    "            edge_index = data[0]['edge_index']\n",
    "            edge_feat = data[0]['edge_feat']\n",
    "            node_feat = data[0]['node_feat']\n",
    "            label = data[1]\n",
    "\n",
    "            # Create adjacency matrix\n",
    "            num_nodes = node_feat.shape[0]\n",
    "            adj = np.zeros((num_nodes, num_nodes))\n",
    "            for edge in edge_index.T:\n",
    "                adj[edge[0], edge[1]] = 1\n",
    "\n",
    "            # Create spektral Graph object\n",
    "            graphs.append(Graph(x=node_feat, a=adj, e=edge_feat, y=label))\n",
    "\n",
    "        return graphs\n",
    "\n",
    "def ogb_available_datasets():\n",
    "    #These regression datasets have size % 2 == 0 number of graphs\n",
    "    return ['ogbg-molesol', 'ogbg-molfreesolv', 'ogbg-mollipo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5122967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(name: str):\n",
    "    '''\n",
    "    Loads a dataset from [TUDataset, OGB]\n",
    "    '''\n",
    "    if name == 'QM9':\n",
    "        dataset = QM9(amount=1000)# 1000 and 100000 ok\n",
    "    elif name in TUDataset.available_datasets():\n",
    "        dataset = TUDataset(name)\n",
    "    elif name in ogb_available_datasets():\n",
    "        dataset= OGBDataset(name)\n",
    "    else:\n",
    "        raise ValueError(f'Dataset {name} unknown')\n",
    "\n",
    "    return dataset, dataset.n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "313cc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_data(data, train_test_split, seed):\n",
    "    '''\n",
    "    Split the data into train and test sets\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    idxs = np.random.permutation(len(data))\n",
    "    split = int(train_test_split * len(data))\n",
    "    idx_train, idx_test = np.split(idxs, [split])\n",
    "    train, test = data[idx_train], data[idx_test]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd00116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(config):\n",
    "    seed = config['seed']\n",
    "    train_test_split = config['train_test_split']\n",
    "    name = config['dataset']\n",
    "\n",
    "    # Load data\n",
    "    data, config['n_out'] = _load_data(name)\n",
    "    # Split data\n",
    "    train_data, test_data = _split_data(data, train_test_split, seed)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58deeaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_signature(signature):\n",
    "    \"\"\"\n",
    "    Converts a Dataset signature to a TensorFlow signature. Extended keys (idx_a, idx_b) for MyDisjointLoader.\n",
    "    :param signature: a Dataset signature.\n",
    "    :return: a TensorFlow signature.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    keys = [\"x\", \"a\", \"e\", \"i\", \"idx_a\", \"idx_b\"]\n",
    "    for k in keys:\n",
    "        if k in signature:\n",
    "            shape = signature[k][\"shape\"]\n",
    "            dtype = signature[k][\"dtype\"]\n",
    "            spec = signature[k][\"spec\"]\n",
    "            output.append(spec(shape, dtype))\n",
    "    output = tuple(output)\n",
    "    if \"y\" in signature:\n",
    "        shape = signature[\"y\"][\"shape\"]\n",
    "        dtype = signature[\"y\"][\"dtype\"]\n",
    "        spec = signature[\"y\"][\"spec\"]\n",
    "        output = (output, spec(shape, dtype))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b36b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDisjointLoader(DisjointLoader):\n",
    "    \"\"\"\n",
    "    Extension of DisjointLoader class from spektral library. Additionally to data and targets, it also returns ranking pair indices.\n",
    "    A Loader for [disjoint mode](https://graphneural.network/data-modes/#disjoint-mode).\n",
    "\n",
    "    This loader represents a batch of graphs via their disjoint union.\n",
    "\n",
    "    The loader automatically computes a batch index tensor, containing integer\n",
    "    indices that map each node to its corresponding graph in the batch.\n",
    "\n",
    "    The adjacency matrix os returned as a SparseTensor, regardless of the input.\n",
    "\n",
    "    If `node_level=False`, the labels are interpreted as graph-level labels and\n",
    "    are stacked along an additional dimension.\n",
    "    If `node_level=True`, then the labels are stacked vertically.\n",
    "\n",
    "    **Note:** TensorFlow 2.4 or above is required to use this Loader's `load()`\n",
    "    method in a Keras training loop.\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "    - `dataset`: a graph Dataset;\n",
    "    - `node_level`: bool, if `True` stack the labels vertically for node-level\n",
    "    prediction;\n",
    "    - `batch_size`: size of the mini-batches;\n",
    "    - `epochs`: number of epochs to iterate over the dataset. By default (`None`)\n",
    "    iterates indefinitely;\n",
    "    - `shuffle`: whether to shuffle the data at the start of each epoch.\n",
    "\n",
    "    **Output**\n",
    "\n",
    "    For each batch, returns a tuple `(inputs, labels)`.\n",
    "\n",
    "    `inputs` is a tuple containing:\n",
    "\n",
    "    - `x`: node attributes of shape `[n_nodes, n_node_features]`;\n",
    "    - `a`: adjacency matrices of shape `[n_nodes, n_nodes]`;\n",
    "    - `e`: edge attributes of shape `[n_edges, n_edge_features]`;\n",
    "    - `i`: batch index of shape `[n_nodes]`.\n",
    "\n",
    "    `labels` have shape `[batch, n_labels]` if `node_level=False` or\n",
    "    `[n_nodes, n_labels]` otherwise.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, dataset, node_level=False, batch_size=1, epochs=None, shuffle=True, seed=42, radius=4, sampling_ratio=100\n",
    "    ):\n",
    "        self.node_level = node_level\n",
    "        super().__init__(dataset, batch_size=batch_size, epochs=epochs, shuffle=shuffle)\n",
    "        self.seed = seed\n",
    "        self.radius = radius\n",
    "        self.sampling_ratio = sampling_ratio\n",
    "\n",
    "    def collate(self, batch):\n",
    "        idx_a, idx_b, target = self.sample_preference_pairs(batch, seed=self.seed, radius=self.radius, sampling_ratio=self.sampling_ratio)\n",
    "        packed = self.pack(batch)\n",
    "\n",
    "        y = packed.pop(\"y_list\", None)\n",
    "        if y is not None:\n",
    "            y = collate_labels_disjoint(y, node_level=self.node_level)\n",
    "\n",
    "        output = to_disjoint(**packed)\n",
    "        output = sp_matrices_to_sp_tensors(output)\n",
    "\n",
    "        return output + (idx_a, idx_b), target\n",
    "\n",
    "    def load(self):\n",
    "        print(\"load\")\n",
    "        if not tf_loader_available:\n",
    "            raise RuntimeError(\n",
    "                \"Calling DisjointLoader.load() requires \" \"TensorFlow 2.4 or greater.\"\n",
    "            )\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            lambda: self, output_signature=self.tf_signature()\n",
    "        )\n",
    "\n",
    "    def tf_signature(self):\n",
    "        \"\"\"\n",
    "        Adjacency matrix has shape [n_nodes, n_nodes]\n",
    "        Node features have shape [n_nodes, n_node_features]\n",
    "        Edge features have shape [n_edges, n_edge_features]\n",
    "        Targets have shape [*, n_labels]\n",
    "        Pairs have shape [*, 2]\n",
    "        \"\"\"\n",
    "        signature = self.dataset.signature\n",
    "        if \"y\" in signature:\n",
    "            signature[\"y\"][\"shape\"] = prepend_none(signature[\"y\"][\"shape\"]) #(12800,) #(None, 1)\n",
    "        if \"a\" in signature:\n",
    "            signature[\"a\"][\"spec\"] = tf.SparseTensorSpec\n",
    "\n",
    "        signature[\"i\"] = dict()\n",
    "        signature[\"i\"][\"spec\"] = tf.TensorSpec\n",
    "        signature[\"i\"][\"shape\"] = (None,)\n",
    "        signature[\"i\"][\"dtype\"] = tf.as_dtype(tf.int64)\n",
    "\n",
    "        signature[\"idx_a\"] = dict()\n",
    "        signature[\"idx_a\"][\"spec\"] = tf.TensorSpec\n",
    "        signature[\"idx_a\"][\"shape\"] = (None,)\n",
    "        signature[\"idx_a\"][\"dtype\"] = tf.as_dtype(tf.int64)\n",
    "        signature[\"idx_b\"] = dict()\n",
    "        signature[\"idx_b\"][\"spec\"] = tf.TensorSpec\n",
    "        signature[\"idx_b\"][\"shape\"] = (None,)\n",
    "        signature[\"idx_b\"][\"dtype\"] = tf.as_dtype(tf.int64)\n",
    "\n",
    "        return to_tf_signature(signature)\n",
    "\n",
    "    def sample_preference_pairs(self, graphs, radius=4, sampling_ratio=100, seed=42):\n",
    "        seed = self.seed\n",
    "        size = len(graphs)\n",
    "        sample_size = size * radius * sampling_ratio\n",
    "        r = np.arange(size)\n",
    "        S = sp.csr_matrix((r, (r, r)), shape=(size, size))\n",
    "        parts = np.split(S.data, S.indptr[1:-1])\n",
    "        rnd = np.random.default_rng(seed)\n",
    "        for part in parts:\n",
    "            rnd.shuffle(part)\n",
    "        idx_a = np.empty((sample_size,), dtype=np.int64)\n",
    "        idx_b = np.empty((sample_size,), dtype=np.int64)\n",
    "        target = np.ones((sample_size,), dtype=np.float64)\n",
    "        k = 0\n",
    "        for i in range(size):\n",
    "            part = parts[i]\n",
    "            psize = len(part)\n",
    "            for d in range(radius):\n",
    "                ni = (i + d + 1) % size\n",
    "                npart = parts[ni]\n",
    "                npsize = len(npart)\n",
    "                for j in range(sampling_ratio):\n",
    "                    npart_offset = np.roll(npart, d * sampling_ratio + j)\n",
    "                    idx_a[k:k + psize] = part\n",
    "                    if npsize < psize:\n",
    "                        idx_b[k:k + npsize] = npart_offset\n",
    "                        idx_b[k + npsize:k + psize] = npart_offset[:psize - npsize]\n",
    "                    else:\n",
    "                        idx_b[k:k + psize] = npart_offset[:psize]\n",
    "                    if ni < i:\n",
    "                        target[k:k + psize] = 0\n",
    "                    k += psize\n",
    "        return idx_a, idx_b, target.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3feb653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a437a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graphs, test_graphs = get_data(config)\n",
    "loader_tr = MyDisjointLoader(train_graphs, batch_size=config['batch_size'], epochs=config['epochs'], seed=config['seed'], radius=4, sampling_ratio=100)\n",
    "loader_te = MyDisjointLoader(test_graphs, batch_size=config['batch_size'], epochs=1, seed=config['seed'], radius=1, sampling_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "880ba961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414, 9)\n",
      "(414, 414)\n",
      "(858, 3)\n",
      "(414,)\n",
      "(12800,)\n",
      "(12800,)\n"
     ]
    }
   ],
   "source": [
    "for b in loader_tr:\n",
    "  print(b[0][0].shape)\n",
    "  print(b[0][1].shape)\n",
    "  print(b[0][2].shape)\n",
    "  print(b[0][3].shape)\n",
    "  print(b[0][4].shape)\n",
    "  print(b[0][5].shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0e4d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pref_lookup(X, pref_a, pref_b):\n",
    "  X_a = tf.gather(X, pref_a, axis=0)\n",
    "  X_b = tf.gather(X, pref_b, axis=0)\n",
    "  return X_a, X_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "174a281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from spektral.layers import GlobalSumPool, ECCConv, GraphMasking\n",
    "\n",
    "\n",
    "class PRGNN(tf.keras.Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.masking = GraphMasking()\n",
    "        self.conv1 = ECCConv(256, activation=\"relu\")\n",
    "        self.conv2 = ECCConv(128, activation=\"relu\")\n",
    "        self.conv3 = ECCConv(64, activation=\"relu\")\n",
    "        self.conv4 = ECCConv(32, activation=\"relu\")\n",
    "        self.conv5 = ECCConv(16, activation=\"relu\")\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.batchnorm = BatchNormalization()\n",
    "        self.global_pool = GlobalSumPool()\n",
    "        self.dense = Dense(config['n_out'], activation='relu')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a, e, i, idx_a, idx_b = inputs\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        a = tf.cast(a, tf.float32)#anpassen\n",
    "        e = tf.cast(e, tf.float32)\n",
    "\n",
    "        x = self.masking(x)\n",
    "        X = self.conv1([x, a, e])\n",
    "        # X = self.dropout(X)\n",
    "        X = self.conv2([X, a, e])\n",
    "        # X = self.dropout(X)\n",
    "        X = self.conv3([X, a, e])\n",
    "        # X = self.dropout(X)\n",
    "        X = self.conv4([X, a, e])\n",
    "        # X = self.dropout(X)\n",
    "        X = self.conv5([X, a, e])\n",
    "        # X = self.dropout(X)\n",
    "\n",
    "        # X = self.global_pool([X, i])\n",
    "        X_util = self.dense(X)\n",
    "        X_a, X_b = self.pref_lookup(X_util, idx_a, idx_b)\n",
    "\n",
    "        return X_b - X_a, X_util\n",
    "\n",
    "    def pref_lookup(self, X, pref_a, pref_b):\n",
    "\n",
    "        X_a = tf.gather(X, pref_a, axis=0)\n",
    "        X_b = tf.gather(X, pref_b, axis=0)\n",
    "\n",
    "        return X_a, X_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b9cd6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from spektral.layers import GlobalSumPool, ECCConv, GraphMasking, GCNConv\n",
    "\n",
    "from keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from keras.metrics import BinaryAccuracy\n",
    "\n",
    "channels = 256  # Number of channels for GCN layers\n",
    "dropout = 0.5  # Dropout rate for the features\n",
    "\n",
    "def createPairwiseModel(config):#als tf function\n",
    "        X_input = tf.keras.Input(shape=(9,), dtype=tf.float32)\n",
    "        a_input = tf.keras.Input(shape=(None,), sparse=True)\n",
    "        e_input = tf.keras.Input(shape=(3,), dtype=tf.float32)\n",
    "        i_input = tf.keras.Input(shape=(None,), dtype=tf.int32)\n",
    "        pref_a = tf.keras.Input(shape=(None,), dtype=tf.int32)\n",
    "        pref_b = tf.keras.Input(shape=(None,), dtype=tf.int32)\n",
    "\n",
    "        _model = PRGNN(config)\n",
    "        out, X_utils = _model([X_input, a_input, e_input, i_input, pref_a, pref_b])\n",
    "\n",
    "        m = tf.keras.Model(inputs=[X_input, a_input, e_input, i_input, pref_a, pref_b], outputs=out, name=\"RankNet\")\n",
    "        m_infer = tf.keras.Model(inputs=[X_input, a_input, e_input, i_input], outputs=X_utils, name=\"RankNet_predictor\")\n",
    "\n",
    "        m.compile(\n",
    "            optimizer=\n",
    "                Adam(config['learning_rate']),\n",
    "                loss=BinaryCrossentropy(from_logits=True),\n",
    "                metrics=[BinaryAccuracy(threshold=.0)]\n",
    "\n",
    "        )\n",
    "\n",
    "        return m, m_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9f7d2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training repeat 1/3...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.int32, name='input_23'), name='input_23', description=\"created by layer 'input_23'\") at layer \"prgnn_3\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-468a97ddfc49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training repeat {i+1}/3...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrn_inf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreatePairwiseModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mrns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrn_inf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-82157340c40c>\u001b[0m in \u001b[0;36mcreatePairwiseModel\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpref_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpref_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RankNet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mm_infer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RankNet_predictor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         m.compile(\n",
      "\u001b[0;32m~/miniconda3/envs/experiment/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/experiment/lib/python3.6/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/experiment/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/experiment/lib/python3.6/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 193\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/experiment/lib/python3.6/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    982\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m    985\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.int32, name='input_23'), name='input_23', description=\"created by layer 'input_23'\") at layer \"prgnn_3\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "rns = []\n",
    "hs = []\n",
    "for i in range(3):\n",
    "  print(f\"Training repeat {i+1}/3...\")\n",
    "  rn, rn_inf = createPairwiseModel(config)\n",
    "  h = rn.fit(loader_tr.load(), validation_data=loader_te.load(), epochs=500, verbose=2)\n",
    "  rns.append(rn_inf)\n",
    "  hs.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d4a358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
